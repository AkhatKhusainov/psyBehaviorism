# psyBehaviorism
annotation
This study proposes an approach that overcomes these limitations through large language model (LLM) reflection—the ability to analyze its own errors and adjust classification criteria. Unlike traditional methods requiring manual coding and triangulation [11], our technology automates the process while preserving decision transparency.

Behavior prediction is achieved through qualitative analysis of texts at any scale, leveraging large language models' capabilities for interpretation and reflection via iterative dialogue.

Цифровая среда стала важным пространством для изучения человеческого поведения: социальные сети, форумы и блоги фиксируют миллионы текстовых взаимодействий, отражающих эмоции, ценности и социальные динамики. Современные большие языковые модели, такие как Claude, GPT, YandexGPT, активно применяются в социологии и психологии для анализа качественных данных, включая интервью, открытые опросы и публичные дискуссии [7]. Их emergent-способности — качественные скачки в решении задач, которые отсутствуют у меньших моделей [14] — делают их перспективным инструментом для классификации поведения. Однако эта задача сталкивается с двумя серьезными проблемами. Во-первых, контекстная зависимость: одно и то же высказывание может нести разный прагматический смысл. Например, фраза «Власти бездействуют» может быть деструктивной (если цель — нагнетание паники) или конструктивной (если далее следует предложение создать общественный совет), что требует глубокого анализа контекста, аналогично задачам в политических исследованиях [6]. Во-вторых, интерпретируемость: сложные модели машинного обучения, включая LLM, часто работают как «черные ящики», что ограничивает их применение в социальных науках, где объяснимость решений существенно важна [4, 5].  
Данное исследование предлагает подход, преодолевающий эти ограничения через рефлексию больших языковых моделей — способность анализировать собственные ошибки и корректировать критерии классификации. В отличие от традиционных способов, требующих ручного кодирования и триангуляции [11] наша технология должна автоматизировать процесс, сохраняя прозрачность решений.
Прогнозирование поведения осуществляться через квалитативный анализ текстов любого объема с использованием возможностей больших языковых моделей к интерпретации и рефлексии через итеративный диалог.

В данном репозитории представлен пайплайн разработки:
"""
.
├── LiveJournal_parser/
│   ├── commander.py   #необходимо ввести имена нужных авторов в список и запустить 
│   ├── li_pars7.py  
│   ├── links_pars4.py
├── Pikabu_parser/
│   └── pikab_pars4.py   #необходимо ввести имена нужных авторов в список и запустить 
├── First_research/
│   ├── Classification/   #первичная классификация(простой промт)
│   └── Доработка/
├── Second_research/
│   ├── table_probabilities_features.py  #отправляет запрос и создает таблицу распределения вероятностей, объяснения и выделяет признаки(0-3)
│   ├── feature_selection.py   #сокращает количество признаков в таблице до 20
│   ├── Logistic_regression.py   #подссчитывает веса и подгоняет их(1000 итераций либо условие остановки) необходимо иметь "првильные" one-hot метки для каждого класса
│   ├── Classification_claude.py    #запускает классификацию, сохраняет результаты в таблицу
│   └── Statistics_output.py     #подсчитывает метрики, визуализирует матрицу ошибок
└── README.md

"""
